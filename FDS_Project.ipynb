{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/bin/pip: line 2: /Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/projectEnv/bin/python: No such file or directory\n",
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/bin/pip: line 2: exec: /Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/projectEnv/bin/python: cannot execute: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn transformers torch sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the dataset\n",
    "\n",
    "df = pd.read_csv('Data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Data</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>61</td>\n",
       "      <td>0.801261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2533</td>\n",
       "      <td>33.272035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Data  Missing Percentage\n",
       "keyword             61            0.801261\n",
       "location          2533           33.272035"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Data Analysis\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data /df.shape[0]) * 100\n",
    "\n",
    "# Create a DataFrame using the two arrays\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Data': missing_data,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}, index=df.columns)\n",
    "\n",
    "# Filter to include only rows with non-zero missing data\n",
    "missing_df_filtered = missing_df[missing_df['Missing Data'] > 0]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "missing_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'location'\n",
    "clean_df = df.drop(columns='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>10830</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and I wrecked you both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                                               text  \\\n",
       "31       48   ablaze  @bbcmtd Wholesale Markets ablaze http://t.co/l...   \n",
       "32       49   ablaze  We always try to bring the heavy. #metal #RT h...   \n",
       "33       50   ablaze  #AFRICANBAZE: Breaking news:Nigeria flag set a...   \n",
       "34       52   ablaze                 Crying out for more! Set me ablaze   \n",
       "35       53   ablaze  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...   \n",
       "...     ...      ...                                                ...   \n",
       "7578  10830  wrecked   @jt_ruff23 @cameronhacker and I wrecked you both   \n",
       "7579  10831  wrecked  Three days off from work and they've pretty mu...   \n",
       "7580  10832  wrecked  #FX #forex #trading Cramer: Iger's 3 words tha...   \n",
       "7581  10833  wrecked  @engineshed Great atmosphere at the British Li...   \n",
       "7582  10834  wrecked  Cramer: Iger's 3 words that wrecked Disney's s...   \n",
       "\n",
       "      target  \n",
       "31         1  \n",
       "32         0  \n",
       "33         1  \n",
       "34         0  \n",
       "35         0  \n",
       "...      ...  \n",
       "7578       0  \n",
       "7579       0  \n",
       "7580       0  \n",
       "7581       0  \n",
       "7582       0  \n",
       "\n",
       "[7552 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where 'keyword' has null values\n",
    "df_cleaned = clean_df.dropna(subset=['keyword'])\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/110014366.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text_embedding'] = df_cleaned['text'].apply(get_bert_embedding)\n",
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/110014366.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['keyword_embedding'] = df_cleaned['keyword'].apply(get_bert_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1302\n",
      "           1       0.83      0.69      0.75       964\n",
      "\n",
      "    accuracy                           0.81      2266\n",
      "   macro avg       0.81      0.79      0.80      2266\n",
      "weighted avg       0.81      0.81      0.80      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to compute BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Average the last hidden state to get a fixed-length vector\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Apply the BERT embedding function to both 'text' and 'keyword' columns\n",
    "df_cleaned['text_embedding'] = df_cleaned['text'].apply(get_bert_embedding)\n",
    "df_cleaned['keyword_embedding'] = df_cleaned['keyword'].apply(get_bert_embedding)\n",
    "\n",
    "# Combine embeddings into a single feature matrix\n",
    "X = np.hstack([np.stack(df_cleaned['text_embedding'].values), np.stack(df_cleaned['keyword_embedding'].values)])\n",
    "y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "\n",
    "\n",
    "# Step 3: Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train a simple classifier, e.g., Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SBERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (7552, 384)\n",
      "Text Embeddings Shape: (7552, 384)\n",
      "\n",
      "Cosine Similarities Matrix:\n",
      "\n",
      "[[1.0000001  0.17108253 0.37499806 ... 0.3040543  0.28843108 0.2948931 ]\n",
      " [0.17108253 0.99999994 0.21963425 ... 0.2392297  0.24595247 0.06717228]\n",
      " [0.37499806 0.21963425 1.         ... 0.19039425 0.30009043 0.17236699]\n",
      " ...\n",
      " [0.3040543  0.2392297  0.19039425 ... 1.0000005  0.28146535 0.8141388 ]\n",
      " [0.28843108 0.24595247 0.30009043 ... 0.28146535 1.0000001  0.27518782]\n",
      " [0.2948931  0.06717228 0.17236699 ... 0.8141388  0.27518782 1.0000001 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/1661363783.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['keyword_embeddings'] = df_cleaned['keyword'].apply(lambda x: model.encode(x))\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Calculate embeddings for 'text' and 'keyword'\n",
    "text_embeddings = model.encode(df_cleaned['text'].tolist())  # Convert 'text' to a list\n",
    "df_cleaned['keyword_embeddings'] = df_cleaned['keyword'].apply(lambda x: model.encode(x))\n",
    "print(f\"Embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# 3. Calculate cosine similarity between text embeddings\n",
    "similarities = cosine_similarity(text_embeddings)\n",
    "\n",
    "print(f\"Text Embeddings Shape: {text_embeddings.shape}\")\n",
    "print(\"\\nCosine Similarities Matrix:\\n\")\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      1302\n",
      "           1       0.83      0.70      0.76       964\n",
      "\n",
      "    accuracy                           0.81      2266\n",
      "   macro avg       0.82      0.80      0.80      2266\n",
      "weighted avg       0.81      0.81      0.81      2266\n",
      "\n",
      "Accuracy :  0.8111209179170344\n"
     ]
    }
   ],
   "source": [
    "# Convert 'keyword_embeddings' to a 2D NumPy array\n",
    "keyword_embeddings = np.vstack(df_cleaned['keyword_embeddings'].values)\n",
    "\n",
    "# Combine embeddings into a single feature matrix\n",
    "X = np.hstack((text_embeddings, keyword_embeddings))\n",
    "y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "#X = embeddings\n",
    "#y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "\n",
    "\n",
    "# Step 3: Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train a simple classifier, e.g., Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy : \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for experiment\n",
    "\n",
    "def experiment(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model :  RandomForestClassifier(n_estimators=2)\n",
      "Accuracy :  0.6972639011473963\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=20)\n",
      "Accuracy :  0.7978817299205648\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier()\n",
      "Accuracy :  0.8093556928508385\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=200)\n",
      "Accuracy :  0.8168578993821712\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=250)\n",
      "Accuracy :  0.8137687555163283\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [2, 20, 100, 200, 250] # number of decision trees\n",
    "\n",
    "accuracy_list = []\n",
    "for ne in n_estimators_list:\n",
    "    (accuracy, model) = experiment(RandomForestClassifier(n_estimators=ne), X, y)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "        \n",
    "    print(\"\\nModel : \", model)\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "    print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model :  RandomForestClassifier(n_estimators=200)\n",
    "## Accuracy :  0.8190644307149162\n",
    "\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=3)\n",
      "max_depth :  3\n",
      "Accuracy :  0.6844660194174758\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=5)\n",
      "max_depth :  5\n",
      "Accuracy :  0.7206531332744925\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=7)\n",
      "max_depth :  7\n",
      "Accuracy :  0.732568402471315\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=10)\n",
      "max_depth :  10\n",
      "Accuracy :  0.7259488084730803\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=15)\n",
      "max_depth :  15\n",
      "Accuracy :  0.7038834951456311\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=20)\n",
      "max_depth :  20\n",
      "Accuracy :  0.6897616946160635\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_depth1 = [3,5,7,10,15,20]\n",
    "\n",
    "for depth in max_depth1:\n",
    "        \n",
    "    (accuracy, model) = experiment(DecisionTreeClassifier(max_depth= depth), X, y)\n",
    "    print(\"\\nModel : \", model)\n",
    "    print(\"max_depth : \", depth)\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kernel : poly\n",
      "Accuracy : 0.8278905560458959\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : linear\n",
      "Accuracy : 0.8265666372462489\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : rbf\n",
      "Accuracy : 0.8305383936451898\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : sigmoid\n",
      "Accuracy : 0.8080317740511915\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "svm_kernel= ['poly','linear','rbf','sigmoid']\n",
    "\n",
    "for svm_ke in svm_kernel:\n",
    "    svm = SVC(C=1, kernel=svm_ke, gamma='scale')  # Linear kernel for binary classification\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "   \n",
    "    print(\"\\nkernel :\", svm_ke)\n",
    "    print(f\"Accuracy : {accuracy}\")\n",
    "    print(\"\\n--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm = SVC(C=1, kernel='rbf', gamma='scale') \n",
    "## Accuracy: 0.8305383936451898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation : relu\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : identity\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : logistic\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : tanh\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nn_activation = ['relu','identity','logistic','tanh']\n",
    "# Step 2: Initialize and train your neural network\n",
    "# Multi-Layer Perceptron (MLP) \n",
    "for nn_act in nn_activation:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,), activation='tanh', max_iter=10000, random_state=42)  \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nActivation :\", nn_act)\n",
    "    print(f\"Accuracy : {accuracy}\")\n",
    "    print(\"\\n--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "clean_df = df.drop(columns='location')\n",
    "clean_test_df = clean_df.dropna(subset=['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (7552, 384)\n",
      "Text Embeddings Shape: (7552, 384)\n",
      "Cosine Similarities Matrix:\n",
      "[[1.0000001  0.17108253 0.37499806 ... 0.3040543  0.28843108 0.2948931 ]\n",
      " [0.17108253 0.99999994 0.21963425 ... 0.2392297  0.24595247 0.06717228]\n",
      " [0.37499806 0.21963425 1.         ... 0.19039425 0.30009043 0.17236699]\n",
      " ...\n",
      " [0.3040543  0.2392297  0.19039425 ... 1.0000005  0.28146535 0.8141388 ]\n",
      " [0.28843108 0.24595247 0.30009043 ... 0.28146535 1.0000001  0.27518782]\n",
      " [0.2948931  0.06717228 0.17236699 ... 0.8141388  0.27518782 1.0000001 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/659444851.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_test_df['keyword_embeddings'] = clean_test_df['keyword'].apply(lambda x: model.encode(x))\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Calculate embeddings for 'text' and 'keyword'\n",
    "text_embeddings = model.encode(clean_test_df['text'].tolist())  # Convert 'text' to a list\n",
    "clean_test_df['keyword_embeddings'] = clean_test_df['keyword'].apply(lambda x: model.encode(x))\n",
    "print(f\"Embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# 3. Calculate cosine similarity between text embeddings\n",
    "similarities = cosine_similarity(text_embeddings)\n",
    "\n",
    "print(f\"Text Embeddings Shape: {text_embeddings.shape}\")\n",
    "print(\"Cosine Similarities Matrix:\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
