{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/bin/pip: line 2: /Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/projectEnv/bin/python: No such file or directory\n",
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/bin/pip: line 2: exec: /Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/projectEnv/bin/python: cannot execute: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn transformers torch sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirthavarshanimahadevan/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the dataset\n",
    "\n",
    "df = pd.read_csv('Data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Data</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>61</td>\n",
       "      <td>0.801261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2533</td>\n",
       "      <td>33.272035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Data  Missing Percentage\n",
       "keyword             61            0.801261\n",
       "location          2533           33.272035"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Data Analysis\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data /df.shape[0]) * 100\n",
    "\n",
    "# Create a DataFrame using the two arrays\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Data': missing_data,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}, index=df.columns)\n",
    "\n",
    "# Filter to include only rows with non-zero missing data\n",
    "missing_df_filtered = missing_df[missing_df['Missing Data'] > 0]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "missing_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'location'\n",
    "clean_df = df.drop(columns='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>10830</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and I wrecked you both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7552 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                                               text  \\\n",
       "31       48   ablaze  @bbcmtd Wholesale Markets ablaze http://t.co/l...   \n",
       "32       49   ablaze  We always try to bring the heavy. #metal #RT h...   \n",
       "33       50   ablaze  #AFRICANBAZE: Breaking news:Nigeria flag set a...   \n",
       "34       52   ablaze                 Crying out for more! Set me ablaze   \n",
       "35       53   ablaze  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...   \n",
       "...     ...      ...                                                ...   \n",
       "7578  10830  wrecked   @jt_ruff23 @cameronhacker and I wrecked you both   \n",
       "7579  10831  wrecked  Three days off from work and they've pretty mu...   \n",
       "7580  10832  wrecked  #FX #forex #trading Cramer: Iger's 3 words tha...   \n",
       "7581  10833  wrecked  @engineshed Great atmosphere at the British Li...   \n",
       "7582  10834  wrecked  Cramer: Iger's 3 words that wrecked Disney's s...   \n",
       "\n",
       "      target  \n",
       "31         1  \n",
       "32         0  \n",
       "33         1  \n",
       "34         0  \n",
       "35         0  \n",
       "...      ...  \n",
       "7578       0  \n",
       "7579       0  \n",
       "7580       0  \n",
       "7581       0  \n",
       "7582       0  \n",
       "\n",
       "[7552 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where 'keyword' has null values\n",
    "df_cleaned = clean_df.dropna(subset=['keyword'])\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/110014366.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text_embedding'] = df_cleaned['text'].apply(get_bert_embedding)\n",
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/110014366.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['keyword_embedding'] = df_cleaned['keyword'].apply(get_bert_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1302\n",
      "           1       0.83      0.69      0.75       964\n",
      "\n",
      "    accuracy                           0.81      2266\n",
      "   macro avg       0.81      0.79      0.80      2266\n",
      "weighted avg       0.81      0.81      0.80      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to compute BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Average the last hidden state to get a fixed-length vector\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Apply the BERT embedding function to both 'text' and 'keyword' columns\n",
    "df_cleaned['text_embedding'] = df_cleaned['text'].apply(get_bert_embedding)\n",
    "df_cleaned['keyword_embedding'] = df_cleaned['keyword'].apply(get_bert_embedding)\n",
    "\n",
    "# Combine embeddings into a single feature matrix\n",
    "X = np.hstack([np.stack(df_cleaned['text_embedding'].values), np.stack(df_cleaned['keyword_embedding'].values)])\n",
    "y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "\n",
    "\n",
    "# Step 3: Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train a simple classifier, e.g., Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SBERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (7552, 384)\n",
      "Text Embeddings Shape: (7552, 384)\n",
      "\n",
      "Cosine Similarities Matrix:\n",
      "\n",
      "[[1.0000001  0.17108253 0.37499806 ... 0.3040543  0.28843108 0.2948931 ]\n",
      " [0.17108253 0.99999994 0.21963425 ... 0.2392297  0.24595247 0.06717228]\n",
      " [0.37499806 0.21963425 1.         ... 0.19039425 0.30009043 0.17236699]\n",
      " ...\n",
      " [0.3040543  0.2392297  0.19039425 ... 1.0000005  0.28146535 0.8141388 ]\n",
      " [0.28843108 0.24595247 0.30009043 ... 0.28146535 1.0000001  0.27518782]\n",
      " [0.2948931  0.06717228 0.17236699 ... 0.8141388  0.27518782 1.0000001 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/1661363783.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['keyword_embeddings'] = df_cleaned['keyword'].apply(lambda x: model.encode(x))\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Calculate embeddings for 'text' and 'keyword'\n",
    "text_embeddings = model.encode(df_cleaned['text'].tolist())  # Convert 'text' to a list\n",
    "df_cleaned['keyword_embeddings'] = df_cleaned['keyword'].apply(lambda x: model.encode(x))\n",
    "print(f\"Embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# 3. Calculate cosine similarity between text embeddings\n",
    "similarities = cosine_similarity(text_embeddings)\n",
    "\n",
    "print(f\"Text Embeddings Shape: {text_embeddings.shape}\")\n",
    "print(\"\\nCosine Similarities Matrix:\\n\")\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      1302\n",
      "           1       0.83      0.70      0.76       964\n",
      "\n",
      "    accuracy                           0.81      2266\n",
      "   macro avg       0.82      0.80      0.80      2266\n",
      "weighted avg       0.81      0.81      0.81      2266\n",
      "\n",
      "Accuracy :  0.8111209179170344\n"
     ]
    }
   ],
   "source": [
    "# Convert 'keyword_embeddings' to a 2D NumPy array\n",
    "keyword_embeddings = np.vstack(df_cleaned['keyword_embeddings'].values)\n",
    "\n",
    "# Combine embeddings into a single feature matrix\n",
    "X = np.hstack((text_embeddings, keyword_embeddings))\n",
    "y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "#X = embeddings\n",
    "#y = df_cleaned['target'].values  # Assuming 'target' is your label column\n",
    "\n",
    "\n",
    "# Step 3: Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train a simple classifier, e.g., Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy : \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for experiment\n",
    "\n",
    "def experiment(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model :  RandomForestClassifier(n_estimators=2)\n",
      "Accuracy :  0.6972639011473963\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=20)\n",
      "Accuracy :  0.7978817299205648\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier()\n",
      "Accuracy :  0.8093556928508385\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=200)\n",
      "Accuracy :  0.8168578993821712\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  RandomForestClassifier(n_estimators=250)\n",
      "Accuracy :  0.8137687555163283\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_estimators_list = [2, 20, 100, 200, 250] # number of decision trees\n",
    "\n",
    "accuracy_list = []\n",
    "for ne in n_estimators_list:\n",
    "    (accuracy, model) = experiment(RandomForestClassifier(n_estimators=ne), X, y)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "        \n",
    "    print(\"\\nModel : \", model)\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "    print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model :  RandomForestClassifier(n_estimators=200)\n",
    "## Accuracy :  0.8190644307149162\n",
    "\n",
    "# --------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=3)\n",
      "max_depth :  3\n",
      "Accuracy :  0.6844660194174758\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=5)\n",
      "max_depth :  5\n",
      "Accuracy :  0.7206531332744925\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=7)\n",
      "max_depth :  7\n",
      "Accuracy :  0.732568402471315\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=10)\n",
      "max_depth :  10\n",
      "Accuracy :  0.7259488084730803\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=15)\n",
      "max_depth :  15\n",
      "Accuracy :  0.7038834951456311\n",
      "--------------------------------------------------------\n",
      "\n",
      "Model :  DecisionTreeClassifier(max_depth=20)\n",
      "max_depth :  20\n",
      "Accuracy :  0.6897616946160635\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_depth1 = [3,5,7,10,15,20]\n",
    "\n",
    "for depth in max_depth1:\n",
    "        \n",
    "    (accuracy, model) = experiment(DecisionTreeClassifier(max_depth= depth), X, y)\n",
    "    print(\"\\nModel : \", model)\n",
    "    print(\"max_depth : \", depth)\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kernel : poly\n",
      "Accuracy : 0.8278905560458959\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : linear\n",
      "Accuracy : 0.8265666372462489\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : rbf\n",
      "Accuracy : 0.8305383936451898\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "kernel : sigmoid\n",
      "Accuracy : 0.8080317740511915\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "svm_kernel= ['poly','linear','rbf','sigmoid']\n",
    "\n",
    "for svm_ke in svm_kernel:\n",
    "    svm = SVC(C=1, kernel=svm_ke, gamma='scale')  # Linear kernel for binary classification\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "   \n",
    "    print(\"\\nkernel :\", svm_ke)\n",
    "    print(f\"Accuracy : {accuracy}\")\n",
    "    print(\"\\n--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm = SVC(C=1, kernel='rbf', gamma='scale') \n",
    "## Accuracy: 0.8305383936451898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activation : relu\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : identity\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : logistic\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Activation : tanh\n",
      "Accuracy : 0.7784642541924095\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nn_activation = ['relu','identity','logistic','tanh']\n",
    "# Step 2: Initialize and train your neural network\n",
    "# Multi-Layer Perceptron (MLP) \n",
    "for nn_act in nn_activation:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,), activation='tanh', max_iter=10000, random_state=42)  \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nActivation :\", nn_act)\n",
    "    print(f\"Accuracy : {accuracy}\")\n",
    "    print(\"\\n--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "clean_df = df.drop(columns='location')\n",
    "clean_test_df = clean_df.dropna(subset=['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (7552, 384)\n",
      "Text Embeddings Shape: (7552, 384)\n",
      "Cosine Similarities Matrix:\n",
      "[[1.0000001  0.17108253 0.37499806 ... 0.3040543  0.28843108 0.2948931 ]\n",
      " [0.17108253 0.99999994 0.21963425 ... 0.2392297  0.24595247 0.06717228]\n",
      " [0.37499806 0.21963425 1.         ... 0.19039425 0.30009043 0.17236699]\n",
      " ...\n",
      " [0.3040543  0.2392297  0.19039425 ... 1.0000005  0.28146535 0.8141388 ]\n",
      " [0.28843108 0.24595247 0.30009043 ... 0.28146535 1.0000001  0.27518782]\n",
      " [0.2948931  0.06717228 0.17236699 ... 0.8141388  0.27518782 1.0000001 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/_hw9vphd3kd8psnxbg4f7dtm0000gn/T/ipykernel_48256/659444851.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_test_df['keyword_embeddings'] = clean_test_df['keyword'].apply(lambda x: model.encode(x))\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Calculate embeddings for 'text' and 'keyword'\n",
    "text_embeddings = model.encode(clean_test_df['text'].tolist())  # Convert 'text' to a list\n",
    "clean_test_df['keyword_embeddings'] = clean_test_df['keyword'].apply(lambda x: model.encode(x))\n",
    "print(f\"Embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# 3. Calculate cosine similarity between text embeddings\n",
    "similarities = cosine_similarity(text_embeddings)\n",
    "\n",
    "print(f\"Text Embeddings Shape: {text_embeddings.shape}\")\n",
    "print(\"Cosine Similarities Matrix:\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': logistic_y_pred\n",
    "})\n",
    "\n",
    "# Decode class labels if necessary\n",
    "results_df['Actual'] = label_encoder.inverse_transform(results_df['Actual'])\n",
    "results_df['Predicted'] = label_encoder.inverse_transform(results_df['Predicted'])\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7552 features, but SVC is expecting 768 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m svm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_pred\n",
      "File \u001b[0;32m~/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/sklearn/svm/_base.py:813\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 813\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/sklearn/svm/_base.py:428\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/sklearn/svm/_base.py:606\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    603\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 606\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    616\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/GSU/Fundamental of DS/Project/FDS_Project/projectEnv/lib/python3.12/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 7552 features, but SVC is expecting 768 features as input."
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1, kernel='rbf', gamma='scale')  # Linear kernel for binary classification\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = svm.predict(similarities)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
